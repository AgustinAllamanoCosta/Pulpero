# Pulpero

### Important Responsibility Notice

**DISCLAIMER**: This software uses AI models to generate analysis and suggestions. The owner and contributors of the code are not responsible for any results, suggestions, or analysis generated by the software. All responses and suggestions must be carefully verified by the end user, as they are generated by an AI model and may contain errors or inaccuracies. Use of this software is at your own risk.

## What's in this repo?

This repository contains code for a multi-IDE and multi-platform plugin that analyzes code and its functionality. It's designed to be native to Neovim but includes adapters for IDEs such as IntelliJ, WebStorm, and VScode. The goal is to offer an experience similar to Copilot but without requiring an internet connection or exposing your code to third parties.

### Why the name Pulpero?

Pulpero refers to the Pulper√≠as (old general stores) of old Buenos Aires. The pulperos were the owners of these establishments who used to give advice to people who came to drink or spend time in their store. I thought it was an appropriate name for an AI that offers code advice.

## How to use it?

- In IDEs: Highlight the code you want to analyze, right-click, and select "analyze".
- In Neovim: Select the code in visual mode and execute the ExpFn command.
- Using the REST API: Make a POST request to http://localhost:8080/explain. The body should contain the code to analyze, and the query param 'lang' should specify the language.

### Requirements

*PENDING*

### Local Installation

For local installation, run the script corresponding to your operating system:

*MacOS*
```bash
chmod +x install.sh && ./install.sh
```

*Linux*
```bash
chmod +x install_linux.sh && ./install_linux.sh
```

*Windows*
```powershell
install.ps1
```

These scripts handle:
1. Downloading and configuring Lua in your operating system
2. Installing LuaRocks as package manager
3. Installing Milua, the miniframework used to create the REST API

Once dependencies are installed, run in the repository root:

```bash
lua ./lua/pulpero/core/init.lua
```

This will start the server at http://localhost:8080/. To verify it's working, access the base URL, which should respond with the message "The server is running".

### Lazy Configuration for Neovim

There are two ways to install the repository with Lazy:

1. For local development (if you want to make modifications):
```lua
{ 'Pulpero', dir="~/path/to/repo/Pulpero", opts = {} },
```

2. For direct installation from GitHub:
```lua
{ 'AgustinAllamanoCosta/Pulpero', opts = {} },
```

The second option will keep you updated with the latest version of the repository.

### Configuration for other IDEs

*IntelliJ*: PENDING
*VScode*: PENDING
*WebStorm*: PENDING

### REST API

The API currently offers two basic endpoints. This API is primarily designed for testing and development, IT IS NOT RECOMMENDED FOR PRODUCTION ENVIRONMENTS as it does not implement security validations.

#### Available Endpoints:

1. **Healthcheck**
   - URL: `http://localhost:8080/`
   - Method: GET
   - Response: "The server is running"

2. **Code Analysis**
   - URL: `http://localhost:8080/explain`
   - Method: POST
   - Body: String with code to analyze
   - Query params: `lang` (code language type)

### Docker Image

*PENDING*

### Troubleshooting

The plugin generates logs in the user's `/tmp` folder:

- **pulpero_debug.log**: Records core steps during analysis, configuration, prompts, and model responses.
- **pulpero_setup.log**: Documents plugin initialization steps.
- **pulpero_command.log**: Shows model engine information (llama.cpp).
- **pulpero_error.log**: Records unexpected errors.

Logs are recreated with each request to maintain a controlled size and facilitate debugging of the last execution.

## How does it work?

Pulpero consists of three main parts:

1. **Lua Core**: Designed primarily for Neovim, it handles:
   - Downloading and configuring the model (currently using TinyLlama-1.1B-Chat)
   - Configuring Llama.cpp as execution engine
   - Managing model parameters
   - Formatting prompts and processing responses

2. **Model Engine**: Uses llama.cpp for AI model execution.

3. **IDE Adapters**: IDEs other than Neovim use a compiled version of the core in C.

The presentation of responses may vary depending on the adapter or interface used, but the integrity of the information generated by the model is always maintained.
